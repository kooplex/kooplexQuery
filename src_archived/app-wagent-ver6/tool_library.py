from langchain_community.utilities.sql_database import SQLDatabase
from langchain_ollama import OllamaLLM
from pydantic import BaseModel, Field
from langchain_core.tools import tool
from typing import Annotated, TypedDict, Literal

import sqlite3
import sql_metadata

# import database_descriptor as dd
# import utils
# import problem_class as pc
# import table_selector as ts
import random

import logging
logger = logging.getLogger(__name__)
import chromadb

globals()["Annotated"] = Annotated  


class explain_database_types(BaseModel):
    """Explain the user question about the database"""
    question: str = Field(str , description="The question itself")
    answer: str = Field(str , description="The answer generated by the tool")
    
# @tool(return_direct=True,args_schema=explain_database_types,infer_schema=False)
@tool(args_schema=explain_database_types,infer_schema=False)
def explain_database_tool(question) -> str:
    """
    Answer the user's question about the database
    """
    
    from langchain.prompts import PromptTemplate
    ollama_host = "http://wfct0p-ollamaapi:11434"
    # ollm = OllamaLLM(base_url=ollama_host, model="qwen2.5-coder:14b")
    ollm = OllamaLLM(base_url=ollama_host, model="llama3.1")
    prompt = PromptTemplate(
        template="""You are a helpful microbiologist who has access to a database containing DNA sequences from sewage samples
        Based on the following context: {context}
        Your task is to 
        - answer simply to the user's question
        - explain the meaning of the words in the context of the question
        - suggest alternative words that could be used in the question
    * Be concise

    Question: {question} 

    """,
        input_variables=["question", "context"],
    )

    files = ["sewage_schema.sql", "table_column_description.txt", "sewage_data_descriptor.txt", "table_description.txt"]
    data = []
    for f in files:
        with open(dirname+f, 'r') as rr:
            data.append(rr.read())
    
    chain = prompt | ollm
    logger.info(f"Generating follow-up question with query: {prompt}")
    response = chain.invoke({"question":question, "context": data})
    logger.info(f"Response: {response}")
    
    return response


class export_answer_types(BaseModel):
    """Export the answer to a file"""

    question: str = Field(str , description="The question itself")
    sql_query: str = Field(str, description="SQL query generated by the tool")
    answer: str = Field(str , description="The answer generated by the tool")
#question: Annotated[str, "The question itself"],
                       #sql_query: Annotated[str, "SQL query generated that generated the answer"],
    #                   answer: Annotated[str, "The answer generated by the tool"]}
    
@tool(return_direct=True,args_schema=export_answer_types,infer_schema=False)
def export_answer_tool(input_dict) -> str:
    """
    Export or save the answer to a file. If OK is returned, the answer has been saved to a file.
    Use this tool if the user requests to save or export the results.
    Expected input is a question, an sql query and the answer to the question.
    """
    
    print(input_dict, type(input_dict))
    if type(input_dict) != type({}):
        input_dict = input_dict.split("\n")[0]
        input_dict = eval(input_dict)
    filename = "app_output_chinook_langgraph.csv"
    try:
        df = pd.read_csv(filename)
        if not df.empty:
            pd.concat([df,pd.DataFrame({'question':[input_dict['question']], 'sql_query': input_dict['sql_query'], 'answer':[input_dict['answer']]  })]).to_csv(filename, index=False)
    except:
        pd.DataFrame({'question':[input_dict['question']], 'sql_query': input_dict['sql_query'], 'answer':[input_dict['answer']]  }).to_csv(filename, index=False)
    #pd.DataFrame({'question':[question], 'sql_query': [sql_query], 'answer':[answer] }).to_csv(f"app_output_chinook.csv")
    # pd.DataFrame({'question':[input_dict['question']], 'sql_query': input_dict['sql_query'], 'answer':[input_dict['answer']]  }).to_csv(filename)
    return "OK"

def consultant_subquestions(question):
    from langchain.prompts import PromptTemplate
    ollama_host = "http://wfct0p-ollamaapi:11434"
    ollm = OllamaLLM(base_url=ollama_host, model="qwen2.5-coder:14b")
    prompt = PromptTemplate(
        template="""You are a helpful sentence analyst. Your task is to analyse the given question and split it into simpler subquestions.
        Example: 'How many samples contain antibiotic resistance genes linked to Amoxicillin resistance?'
        Question split into simopler questions: 
        - 'Which genes are linked to Amoxicillin resistance?'
        - 'Which samples contain these resistance genes?'
        - 'How many of these samples are there?'

    * Be concise

    New question: {question} 

    """,
        input_variables=["question"],
    )

    chain = prompt | ollm
    response = chain.invoke({"question":question})
    
    return response

def consultant_words(question):
    from langchain.prompts import PromptTemplate
    ollama_host = "http://wfct0p-ollamaapi:11434"
    ollm = OllamaLLM(base_url=ollama_host, model="qwen2.5-coder:14b")
    prompt = PromptTemplate(
        template="""You are a helpful analyst of the meaning of the words in a question. 
        Based on the following context: {context}
        Your task is to 
        - show which words in the question are important and why
        - explain the meaning of the words in the context of the question
        - suggest alternative words that could be used in the question
    * Be concise

    Question: {question} 

    """,
        input_variables=["question"],
    )

    chain = prompt | ollm
    response = chain.invoke({"question":question})
    
    return response

def dummy(question):
    queries_and_answers = [
        ("SELECT COUNT(*) FROM Orders;", "150"),
        ("SELECT AVG(TotalAmount) FROM Sales;", "350.75"),
        ("SELECT MAX(Salary) FROM Employees;", "120000"),
        ("SELECT MIN(Age) FROM Customers;", "18"),
        ("SELECT SUM(Quantity) FROM Inventory;", "5000"),
        ("SELECT COUNT(DISTINCT Country) FROM Customers;", "25"),
        ("SELECT AVG(Rating) FROM Reviews;", "4.3"),
        ("SELECT MAX(Price) FROM Products;", "999.99"),
        ("SELECT MIN(Year) FROM Movies;", "1920"),
        ("SELECT SUM(Duration) FROM Tracks;", "12345")
    ]

    sql, answer = random.choice(queries_and_answers)
    print(f"SQL query: {sql}\nAnswer: {answer}")
    return f"SQL query: {sql}\n\nAnswer: {answer}"

def submit_query_to_db_sewage(query):
    conn_info = utils.read_dict_from_file('/v/wfct0p/API-tokens/sewage16-postgresql-connection-info.json')
    db = SQLDatabase.from_uri(f"postgresql+psycopg2://{conn_info['user']}:{conn_info['password']}@{conn_info['server']}/{conn_info['database']}", schema=conn_info['schema'])
    resp = db.run(query)
    return resp

def translate_to_sql_tool():
    pass

def tool_for_sewage_db(question):
    conn_info = utils.read_dict_from_file('/v/wfct0p/API-tokens/sewage16-postgresql-connection-info.json')
    db = SQLDatabase.from_uri(f"postgresql+psycopg2://{conn_info['user']}:{conn_info['password']}@{conn_info['server']}/{conn_info['database']}", schema=conn_info['schema'])
    return _tool_for_db(question, db, chromadb_prefix="sewage")    


def tool_for_chinook_db(question):
    
    db_path_chinook = "data/Chinook_Sqlite.sqlite"
    #print(question)
    db = SQLDatabase.from_uri(f"sqlite:///{db_path_chinook}")
    return _tool_for_db(question, db, chromadb_prefix="chinook")

def _tool_for_db(question, db, chromadb_prefix):
    ollama_host = "http://wfct0p-ollamaapi:11434"
    ollm = OllamaLLM(base_url=ollama_host, model="llama3.2")
    sql_llm = OllamaLLM(base_url=ollama_host, model="qwen2.5-coder:14b")
    #sql_llm = OllamaLLM(base_url=ollama_host, model="deepseek-coder:6.7b")
    Otrain = utils.get_train_data(f"{chromadb_prefix}_test.db")
    Otrain['tables_to_use'] = Otrain['sql_query'].apply(lambda x: sql_metadata.Parser(x).tables)    
    examples_dict = Otrain.rename(columns={'sql_query':'sql'})[['question', 'sql']].to_dict(orient='records')
    inspector = dd.DatabaseInspector(ollm = ollm, db_connection=db)
    #sub_examples_dict = [ ex if (ex['question'] != question) else {"question":"","sql":""} for ex in examples_dict]
    
    inspector = dd.DatabaseInspector(ollm = ollm, db_connection=db)
    # TS = ts.TableSelector(question = question, 
    #                     db = db, 
    #                     ollm = ollm, 
    #                     prefix=chromadb_prefix,
    #                     examples=examples_dict)
    # table_names_to_use, dbschema = TS.table_selector()
    dbschema = inspector.describe_database()
    #print(f"Database schema: {dbschema}")
    sub_examples_dict = [ ex if (ex['question'] != question) else {"question":"","sql":""} for ex in examples_dict]
    sql_gen, prompt = utils.run_with_fewshot_prompt(sql_llm, question, db_schema=dbschema, db=db, examples_dict=examples_dict)
    sql_gen['result'] = utils.postprocess_sql(sql_gen['result']) 
    #print(sql_gen['result'])
    try:       
        answer = db.run(sql_gen['result'])
        #print(f"SQL query: {sql_gen['result']}\nAnswer: {answer}")
        #return [{"sql_query": sql_gen['result'], 'answer': answer}]
        return f" SQL query: {sql_gen['result']}\n\n Answer: {answer}"
        #return answer
    except Exception as e:
        return f"SQL query: {sql_gen['result']}\nThere was an error: {e}"

def tool_info_chinook_db(question):
    db_path_chinook = "data/Chinook_Sqlite.sqlite"
    db = SQLDatabase.from_uri(f"sqlite:///{db_path_chinook}")
    return _tool_info_db(question, db, chromadb_prefix="chinook")

def _tool_info_db(question, db, chromadb_prefix):
    ollama_host = "http://wfct0p-ollamaapi:11434"
    ollm = OllamaLLM(base_url=ollama_host, model="llama3.1", keep_alive=1)
    Otrain = utils.get_train_data(f"{chromadb_prefix}_test.db")
    Otrain['tables_to_use'] = Otrain['sql_query'].apply(lambda x: sql_metadata.Parser(x).tables)    
    examples_dict = Otrain.rename(columns={'sql_query':'sql'})[['question', 'sql']].to_dict(orient='records')

    from langchain_chroma import Chroma
    from langchain_core.example_selectors import SemanticSimilarityExampleSelector
    import chromadb
    chromadb.api.client.SharedSystemClient.clear_system_cache()

    example_selector = SemanticSimilarityExampleSelector.from_examples(
        # This is the list of examples available to select from.
        examples_dict,
        # This is the embedding class used to produce embeddings which are used to measure semantic similarity.
        utils.embeddings,
        # This is the VectorStore class that is used to store the embeddings and do a similarity search over.
        Chroma,
        # This is the number of examples to produce.
        k=3,
    )

    TS = ts.TableSelector(question = question, 
                            db = db, 
                            ollm = ollm, 
                            prefix=chromadb_prefix,
                            examples=examples_dict,
                            table_names=False)
    TS.retrieve_info()
    return TS.retriever.invoke(input=question)
    
